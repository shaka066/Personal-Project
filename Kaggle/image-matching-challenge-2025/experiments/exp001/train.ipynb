{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "54864b93",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2.7.0+cu118\n",
                        "CUDA available: True\n",
                        "GPU count: 1\n",
                        "GPU name: NVIDIA GeForce RTX 4070 Laptop GPU\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "print(torch.__version__)                # 例: 2.1.0+cu118\n",
                "print(\"CUDA available:\", torch.cuda.is_available())\n",
                "print(\"GPU count:\", torch.cuda.device_count())\n",
                "if torch.cuda.is_available():\n",
                "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "6335e684",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\337587\\PlayGround\\01_Personal\\Kaggle\\image-matching-challenge-2025\\venv01\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from transformers import AutoImageProcessor, AutoModel\n",
                "from time import time\n",
                "\n",
                "\n",
                "\n",
                "# まずは画像読み込みとグローバル特徴量取得の関数を定義\n",
                "def load_torch_image(fname, device=torch.device('cpu')):\n",
                "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
                "    return img\n",
                "\n",
                "\n",
                "# Must Use efficientnet global descriptor to get matching shortlists.\n",
                "def get_global_desc(fnames, device = torch.device('cpu')):\n",
                "    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
                "    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
                "    model = model.eval()\n",
                "    model = model.to(device)\n",
                "    global_descs_dinov2 = []\n",
                "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
                "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
                "        timg = load_torch_image(img_fname_full)\n",
                "        with torch.inference_mode():\n",
                "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
                "            outputs = model(**inputs)\n",
                "            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n",
                "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
                "    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n",
                "    return global_descs_dinov2\n",
                "\n",
                "\n",
                "def get_img_pairs_exhaustive(img_fnames):\n",
                "    index_pairs = []\n",
                "    for i in range(len(img_fnames)):\n",
                "        for j in range(i+1, len(img_fnames)):\n",
                "            index_pairs.append((i,j))\n",
                "    return index_pairs\n",
                "\n",
                "\n",
                "def get_image_pairs_shortlist(fnames,\n",
                "                              sim_th = 0.6, # should be strict\n",
                "                              min_pairs = 30,\n",
                "                              exhaustive_if_less = 20,\n",
                "                              device=torch.device('cpu')):\n",
                "    num_imgs = len(fnames)\n",
                "    if num_imgs <= exhaustive_if_less:\n",
                "        return get_img_pairs_exhaustive(fnames)\n",
                "    descs = get_global_desc(fnames, device=device)\n",
                "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
                "    # removing half\n",
                "    mask = dm <= sim_th\n",
                "    total = 0\n",
                "    matching_list = []\n",
                "    ar = np.arange(num_imgs)\n",
                "    already_there_set = []\n",
                "    for st_idx in range(num_imgs-1):\n",
                "        mask_idx = mask[st_idx]\n",
                "        to_match = ar[mask_idx]\n",
                "        if len(to_match) < min_pairs:\n",
                "            to_match = np.argsort(dm[st_idx])[:min_pairs]  \n",
                "        for idx in to_match:\n",
                "            if st_idx == idx:\n",
                "                continue\n",
                "            if dm[st_idx, idx] < 1000:\n",
                "                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n",
                "                total+=1\n",
                "    matching_list = sorted(list(set(matching_list)))\n",
                "    return matching_list\n",
                "\n",
                "def detect_aliked(img_fnames,\n",
                "                  feature_dir = '.featureout',\n",
                "                  num_features = 4096,\n",
                "                  resize_to = 1024,\n",
                "                  device=torch.device('cpu')):\n",
                "    dtype = torch.float32 # ALIKED has issues with float16\n",
                "    extractor = ALIKED(max_num_keypoints=num_features, detection_threshold=0.01, resize=resize_to).eval().to(device, dtype)\n",
                "    if not os.path.isdir(feature_dir):\n",
                "        os.makedirs(feature_dir)\n",
                "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
                "         h5py.File(f'{feature_dir}/descriptors.h5', mode='w') as f_desc:\n",
                "        for img_path in tqdm(img_fnames):\n",
                "            img_fname = img_path.split('/')[-1]\n",
                "            key = img_fname\n",
                "            with torch.inference_mode():\n",
                "                image0 = load_torch_image(img_path, device=device).to(dtype)\n",
                "                feats0 = extractor.extract(image0)  # auto-resize the image, disable with resize=None\n",
                "                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy()\n",
                "                descs = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy()\n",
                "                f_kp[key] = kpts\n",
                "                f_desc[key] = descs\n",
                "    return\n",
                "\n",
                "def match_with_lightglue(img_fnames,\n",
                "                   index_pairs,\n",
                "                   feature_dir = '.featureout',\n",
                "                   device=torch.device('cpu'),\n",
                "                   min_matches=25,verbose=True):\n",
                "    lg_matcher = KF.LightGlueMatcher(\"aliked\", {\"width_confidence\": -1,\n",
                "                                                \"depth_confidence\": -1,\n",
                "                                                 \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n",
                "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='r') as f_kp, \\\n",
                "        h5py.File(f'{feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n",
                "        h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
                "        for pair_idx in tqdm(index_pairs):\n",
                "            idx1, idx2 = pair_idx\n",
                "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
                "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
                "            kp1 = torch.from_numpy(f_kp[key1][...]).to(device)\n",
                "            kp2 = torch.from_numpy(f_kp[key2][...]).to(device)\n",
                "            desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n",
                "            desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n",
                "            with torch.inference_mode():\n",
                "                dists, idxs = lg_matcher(desc1,\n",
                "                                         desc2,\n",
                "                                         KF.laf_from_center_scale_ori(kp1[None]),\n",
                "                                         KF.laf_from_center_scale_ori(kp2[None]))\n",
                "            if len(idxs)  == 0:\n",
                "                continue\n",
                "            n_matches = len(idxs)\n",
                "            if verbose:\n",
                "                print (f'{key1}-{key2}: {n_matches} matches')\n",
                "            group  = f_match.require_group(key1)\n",
                "            if n_matches >= min_matches:\n",
                "                 group.create_dataset(key2, data=idxs.detach().cpu().numpy().reshape(-1, 2))\n",
                "    return\n",
                "\n",
                "def import_into_colmap(img_dir, feature_dir ='.featureout', database_path = 'colmap.db'):\n",
                "    db = COLMAPDatabase.connect(database_path)\n",
                "    db.create_tables()\n",
                "    single_camera = False\n",
                "    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', single_camera)\n",
                "    add_matches(\n",
                "        db,\n",
                "        feature_dir,\n",
                "        fname_to_id,\n",
                "    )\n",
                "    db.commit()\n",
                "    return"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc615dd1",
            "metadata": {},
            "source": [
                "## 本編"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "592f83a5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\337587\\PlayGround\\01_Personal\\Kaggle\\image-matching-challenge-2025\\venv01\\Lib\\site-packages\\lightglue\\lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
                        "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "running on cuda\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "wandb: Currently logged in as: shaka066 (shaka066-personal) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "creating run (0.0s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.19.10"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>c:\\Users\\337587\\PlayGround\\01_Personal\\Kaggle\\image-matching-challenge-2025\\experiments\\exp001\\wandb\\run-20250504_013240-cr4e6j4x</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/shaka066-personal/image-matching-challenge/runs/cr4e6j4x' target=\"_blank\">exp_001</a></strong> to <a href='https://wandb.ai/shaka066-personal/image-matching-challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/shaka066-personal/image-matching-challenge' target=\"_blank\">https://wandb.ai/shaka066-personal/image-matching-challenge</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/shaka066-personal/image-matching-challenge/runs/cr4e6j4x' target=\"_blank\">https://wandb.ai/shaka066-personal/image-matching-challenge/runs/cr4e6j4x</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shaka066-personal/image-matching-challenge/runs/cr4e6j4x?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
                        ],
                        "text/plain": [
                            "<wandb.sdk.wandb_run.Run at 0x14f5b8fae50>"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import torch\n",
                "import wandb\n",
                "from lightglue import ALIKED, LightGlue\n",
                "# 実験 ID\n",
                "exp_num = \"001\"\n",
                "\n",
                "# デバイス設定\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"running on {device}\")\n",
                "\n",
                "# W&B 初期化（ベースラインのハイパーパラメータを追加）\n",
                "wandb.init(\n",
                "    project=\"image-matching-challenge\",\n",
                "    name=f\"exp_{exp_num}\",\n",
                "    config={\n",
                "        \"exp_num\": exp_num,\n",
                "        \"device\": str(device),\n",
                "        # ショートリスト用\n",
                "        \"sim_th\": 0.3,\n",
                "        \"min_pairs\": 20,\n",
                "        \"exhaustive_if_less\": 20,\n",
                "        # 特徴抽出（ALIKED）用\n",
                "        \"num_features\": 4096,\n",
                "        \"resize_to\": 1024,\n",
                "        \"detection_threshold\": 0.01,\n",
                "        # LightGlueMatcher 用\n",
                "        \"width_confidence\": -1,\n",
                "        \"depth_confidence\": -1,\n",
                "        \"mp\": True,  # CUDA 使用時に並列化\n",
                "        # COLMAP マッピング設定\n",
                "        \"mapper_min_model_size\": 3,\n",
                "        \"mapper_max_num_models\": 25,\n",
                "    }\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "543e40dc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1) Kaggle API でデータをダウンロード＆展開\n",
                "# DATA_DIR にダウンロード先を指定\n",
                "DATA_DIR = r\"C:\\Users\\337587\\PlayGround\\01_Personal\\Kaggle\\image-matching-challenge-2025\\data\"\n",
                "os.makedirs(DATA_DIR, exist_ok=True)\n",
                "\n",
                "# コマンドライン経由\n",
                "#!kaggle competitions download -c image-matching-challenge-2025 -p {DATA_DIR}\n",
                "\n",
                "# ZIP ファイルを展開\n",
                "#import zipfile\n",
                "#zip_path = os.path.join(DATA_DIR, \"image-matching-challenge-2025.zip\")\n",
                "#with zipfile.ZipFile(zip_path, 'r') as z:\n",
                "#    z.extractall(DATA_DIR)\n",
                "\n",
                "\n",
                "# ダウンロード完了後、ディレクトリ構成を確認\n",
                "#print(\"Downloaded files:\")\n",
                "#for root, dirs, files in os.walk(DATA_DIR):\n",
                "#    level = root.replace(DATA_DIR, '').count(os.sep)\n",
                "#    indent = ' ' * 2 * level\n",
                "#    print(f\"{indent}{os.path.basename(root)}/\")\n",
                "#    for f in files:\n",
                "#        print(f\"{indent}  - {f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "372069cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Kaggle → ローカル用に書き換え\n",
                "DATA_ROOT =  r\"C:\\Users\\337587\\PlayGround\\01_Personal\\Kaggle\\image-matching-challenge-2025\\data\"\n",
                "TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
                "TEST_DIR  = os.path.join(DATA_ROOT, \"test\")\n",
                "\n",
                "# サンプル提出ファイル\n",
                "SAMPLE_SUB_CSV = os.path.join(DATA_ROOT, \"sample_submission.csv\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "3155ab47",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 結果＆モデル保存先\n",
                "RESULTS_DIR = f\"../../results/exp{exp_num}\"\n",
                "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "c2edcc3b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "0it [00:00, ?it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded LightGlue model\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "0it [00:00, ?it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Submission CSV saved to ./results/exp001\\submission.csv\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import glob\n",
                "import h5py\n",
                "from time import time\n",
                "from tqdm import tqdm\n",
                "\n",
                "import wandb\n",
                "import kornia.feature as KF\n",
                "\n",
                "# ————————————————\n",
                "# 定数・パス設定\n",
                "# ————————————————\n",
                "TRAIN_DIR   = \"./data/image-matching-challenge-2025/train\"\n",
                "RESULTS_DIR = f\"./results/exp{exp_num}\"\n",
                "# 出力フォルダが無ければ作成\n",
                "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
                "\n",
                "# ————————————————\n",
                "# 1) 画像パスの収集\n",
                "# ————————————————\n",
                "image_paths = sorted(glob.glob(os.path.join(TRAIN_DIR, \"*\", \"*.*\")))\n",
                "wandb.log({\"n_images\": len(image_paths)})\n",
                "\n",
                "# ————————————————\n",
                "# 2) ショートリスト作成\n",
                "# ————————————————\n",
                "index_pairs = get_image_pairs_shortlist(\n",
                "    image_paths,\n",
                "    sim_th=wandb.config.sim_th,\n",
                "    min_pairs=wandb.config.min_pairs,\n",
                "    exhaustive_if_less=wandb.config.exhaustive_if_less,\n",
                "    device=device\n",
                ")\n",
                "wandb.log({\"n_pairs\": len(index_pairs)})\n",
                "\n",
                "# ————————————————\n",
                "# 3) 特徴検出 (ALIKED)\n",
                "# ————————————————\n",
                "feature_dir = os.path.join(RESULTS_DIR, \"featureout\")\n",
                "os.makedirs(feature_dir, exist_ok=True)\n",
                "\n",
                "t0 = time()\n",
                "detect_aliked(\n",
                "    img_fnames= image_paths,\n",
                "    feature_dir= feature_dir,\n",
                "    num_features= wandb.config.num_features,\n",
                "    resize_to=     wandb.config.resize_to,\n",
                "    device=        device\n",
                ")\n",
                "wandb.log({\"feature_detection_time\": time() - t0})\n",
                "\n",
                "# ————————————————\n",
                "# 4) 特徴マッチング (LightGlue)\n",
                "# ————————————————\n",
                "t0 = time()\n",
                "match_with_lightglue(\n",
                "    img_fnames=   image_paths,\n",
                "    index_pairs=  index_pairs,\n",
                "    feature_dir=  feature_dir,\n",
                "    device=       device,\n",
                "    min_matches=  wandb.config.min_pairs,\n",
                "    verbose=      False\n",
                ")\n",
                "wandb.log({\"feature_matching_time\": time() - t0})\n",
                "\n",
                "# ————————————————\n",
                "# 5) マッチ数を集計してログ\n",
                "# ————————————————\n",
                "matches_h5    = os.path.join(feature_dir, \"matches.h5\")\n",
                "total_matches = 0\n",
                "with h5py.File(matches_h5, \"r\") as f_match:\n",
                "    for grp in f_match.values():\n",
                "        for ds in grp.values():\n",
                "            total_matches += ds.shape[0]\n",
                "wandb.log({\"n_total_matches\": total_matches})\n",
                "# ————————————————\n",
                "# 6) 提出用 CSV の作成＆ W&B アーティファクト化\n",
                "# ————————————————\n",
                "import pandas as pd\n",
                "\n",
                "# サンプル提出フォーマットを読み込む\n",
                "# (上部で SAMPLE_SUB_CSV を定義済みのこと)\n",
                "sub_df = pd.read_csv(SAMPLE_SUB_CSV)\n",
                "\n",
                "# ── ここに、samples（もしくは predictions）から得られた\n",
                "#     rotation_matrix, translation_vector を sub_df に書き込む処理を入れてください。\n",
                "# 例:\n",
                "# sub_df['rotation_matrix']    = my_rotations_list\n",
                "# sub_df['translation_vector'] = my_translations_list\n",
                "\n",
                "# ファイルとして保存\n",
                "out_csv = os.path.join(RESULTS_DIR, \"submission.csv\")\n",
                "sub_df.to_csv(out_csv, index=False)\n",
                "\n",
                "# W&B にアーティファクトとしてアップロード\n",
                "sub_art = wandb.Artifact(\n",
                "    name=f\"submission-exp{exp_num}\",\n",
                "    type=\"submission\",\n",
                "    description=\"Submission CSV for exp_\" + exp_num\n",
                ")\n",
                "sub_art.add_file(out_csv)\n",
                "wandb.log_artifact(sub_art)\n",
                "\n",
                "print(f\"Submission CSV saved to {out_csv}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2571566e",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv01",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
